version: '3.8'

services:
  # --- Kafka stack ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"

  # --- Airflow DB ---
  airflow-db:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  # --- Airflow Webserver ---
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-db:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      AIRFLOW__WEBSERVER__WORKERS: 1
      AIRFLOW__WEBSERVER__WORKER_CLASS: sync
      AIRFLOW__WEBSERVER__WORKER_TIMEOUT: 240
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__SECRET_KEY: "supersecretkey"
      PYTHONPATH: /opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./delta:/opt/airflow/delta
      - ./logs:/opt/airflow/logs
      - ./scripts/init-airflow.sh:/opt/airflow/init-airflow.sh
      - ./jars:/opt/airflow/jars
    ports:
      - "8080:8080"
    command: >
      bash -c "/opt/airflow/init-airflow.sh"
    mem_limit: 2g
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # --- Airflow Scheduler ---
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-db:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: "supersecretkey"
      PYTHONPATH: /opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - ./delta:/opt/airflow/delta
      - ./jars:/opt/airflow/jars
    command: airflow scheduler
    mem_limit: 2g

  # --- MLflow ---
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.15.0
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --artifacts-destination /mlruns
      --serve-artifacts
    volumes:
      - ./mlruns:/mlruns
      - ./mlflow:/mlflow      # <-- mount a folder for the DB file
    ports:
      - "5001:5000"

  # --- Recommender API ---
  reco_api:
    build:
      context: .
      dockerfile: Dockerfile.reco_api
    container_name: reco_api
    depends_on:
      - kafka
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src
      - ./model_lightfm.pkl:/app/model_lightfm.pkl
      - ./dags:/opt/airflow/dags
    mem_limit: 2g
